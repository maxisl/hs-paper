%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Maximilian Slapnik at 2023-07-15 11:23:41 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{wang_reprompt_2023,
	abstract = {Generative AI models have shown impressive ability to produce images with text prompts, which could benefit creativity in visual art creation and self-expression. However, it is unclear how precisely the generated images express contexts and emotions from the input texts. We explored the emotional expressiveness of AI-generated images and developed RePrompt, an automatic method to refine text prompts toward precise expression of the generated images. Inspired by crowdsourced editing strategies, we curated intuitive text features, such as the number and concreteness of nouns, and trained a proxy model to analyze the feature effects on the AI-generated image. With model explanations of the proxy model, we curated a rubric to adjust text prompts to optimize image generation for precise emotion expression. We conducted simulation and user studies, which showed that RePrompt significantly improves the emotional expressiveness of AI-generated images, especially for negative emotions.},
	address = {Hamburg Germany},
	author = {Wang, Yunlong and Shen, Shuyuan and Lim, Brian Y},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	date-added = {2023-07-15 11:23:40 +0200},
	date-modified = {2023-07-15 11:23:40 +0200},
	doi = {10.1145/3544548.3581402},
	file = {Wang et al. - 2023 - RePrompt Automatic Prompt Editing to Refine AI-Ge.pdf:/Users/maximilianslapnik/Zotero/storage/AIPZ65AF/Wang et al. - 2023 - RePrompt Automatic Prompt Editing to Refine AI-Ge.pdf:application/pdf},
	isbn = {978-1-4503-9421-5},
	language = {en},
	month = apr,
	pages = {1--29},
	publisher = {ACM},
	shorttitle = {{RePrompt}},
	title = {{RePrompt}: {Automatic} {Prompt} {Editing} to {Refine} {AI}-{Generative} {Art} {Towards} {Precise} {Expressions}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581402},
	urldate = {2023-07-15},
	year = {2023},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/3544548.3581402},
	bdsk-url-2 = {https://doi.org/10.1145/3544548.3581402}}

@misc{hertz_prompt--prompt_2022,
	abstract = {Recent large-scale text-driven synthesis models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Such text-based synthesis methods are particularly appealing to humans who are used to verbally describe their intent. Therefore, it is only natural to extend the text-driven image synthesis to text-driven image editing. Editing is challenging for these generative models, since an innate property of an editing technique is to preserve most of the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-toprompt editing framework, where the edits are controlled by text only. To this end, we analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we present several applications which monitor the image synthesis by editing the textual prompt only. This includes localized editing by replacing a word, global editing by adding a specification, and even delicately controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts, demonstrating high-quality synthesis and fidelity to the edited prompts.},
	author = {Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
	date-added = {2023-07-15 08:47:45 +0200},
	date-modified = {2023-07-15 08:47:45 +0200},
	file = {Hertz et al. - 2022 - Prompt-to-Prompt Image Editing with Cross Attentio.pdf:/Users/maximilianslapnik/Zotero/storage/W37UWTLA/Hertz et al. - 2022 - Prompt-to-Prompt Image Editing with Cross Attentio.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning},
	language = {en},
	month = aug,
	note = {arXiv:2208.01626 [cs]},
	publisher = {arXiv},
	title = {Prompt-to-{Prompt} {Image} {Editing} with {Cross} {Attention} {Control}},
	url = {http://arxiv.org/abs/2208.01626},
	urldate = {2023-07-15},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2208.01626}}

@misc{oppenlaender_taxonomy_2023,
	abstract = {JONAS OPPENLAENDER, University of Jyv{\"a}skyl{\"a}, Finland Text-guided synthesis of images has become enormously popular and online communities dedicated to textto-image generation and art generated with Artificial Intelligence (AI) have emerged. While deep generative models can synthesize high-quality images and artworks from simple descriptive text prompts, practitioners of text-to-image generation typically seek to control the generative model's output by adding short key phrases (``modifiers'') to the prompt. This paper identifies six types of prompt modifiers used by practitioners in the online text-to-image community based on a 3-month ethnographic study. The novel taxonomy of prompt modifiers provides researchers a conceptual starting point for investigating the practice of text-to-image generation, but may also help practitioners of AI generated art improve their images. We further outline how prompt modifiers are applied in the practice of ``prompt engineering.'' We discuss research opportunities of this novel creative practice in the field of Human-Computer Interaction (HCI). The paper concludes with a discussion of broader implications of prompt engineering from the perspective of Human-AI Interaction (HAI) in future applications beyond the use case of text-to-image generation and AI generated art.},
	author = {Oppenlaender, Jonas},
	date-added = {2023-07-12 11:08:56 +0200},
	date-modified = {2023-07-12 11:08:56 +0200},
	file = {Oppenlaender - 2023 - A Taxonomy of Prompt Modifiers for Text-To-Image G.pdf:/Users/maximilianslapnik/Zotero/storage/4SBI83KC/Oppenlaender - 2023 - A Taxonomy of Prompt Modifiers for Text-To-Image G.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, H.m, Computer Science - Multimedia, H.5, J.5},
	language = {en},
	month = jun,
	note = {arXiv:2204.13988 [cs]},
	publisher = {arXiv},
	title = {A {Taxonomy} of {Prompt} {Modifiers} for {Text}-{To}-{Image} {Generation}},
	url = {http://arxiv.org/abs/2204.13988},
	urldate = {2023-07-03},
	year = {2023},
	bdsk-url-1 = {http://arxiv.org/abs/2204.13988}}

@misc{dhariwal_diffusion_2021,
	abstract = {We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128×128, 4.59 on ImageNet 256×256, and 7.72 on ImageNet 512×512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256×256 and 3.85 on ImageNet 512×512. We release our code at https://github.com/openai/guided-diffusion.},
	author = {Dhariwal, Prafulla and Nichol, Alex},
	date-added = {2023-07-06 11:07:37 +0200},
	date-modified = {2023-07-06 11:07:37 +0200},
	file = {Dhariwal and Nichol - 2021 - Diffusion Models Beat GANs on Image Synthesis.pdf:/Users/maximilianslapnik/Zotero/storage/GBPFT45B/Dhariwal and Nichol - 2021 - Diffusion Models Beat GANs on Image Synthesis.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	language = {en},
	month = jun,
	note = {arXiv:2105.05233 [cs, stat]},
	publisher = {arXiv},
	title = {Diffusion {Models} {Beat} {GANs} on {Image} {Synthesis}},
	url = {http://arxiv.org/abs/2105.05233},
	urldate = {2023-07-06},
	year = {2021},
	bdsk-url-1 = {http://arxiv.org/abs/2105.05233}}

@misc{ge_openagi_2023,
	abstract = {Human intelligence excels at combining basic skills to solve complex tasks. This capability is vital for Artificial Intelligence (AI) and should be embedded in comprehensive intelligent models, enabling them to harness expert models for complex task-solving towards Artificial General Intelligence (AGI). Large Language Models (LLMs) show promising learning and reasoning abilities, and can effectively use external models to tackle complex problems. In this work, we introduce OpenAGI, an open-source AGI research platform designed for multi-step, real-world tasks. Specifically, OpenAGI uses a dual strategy, integrating standard benchmark tasks for benchmarking and evaluation, and open-ended tasks including more expandable models for creative problem-solving. Tasks are presented as natural language queries to the LLM, which then selects and executes appropriate models. We also propose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses task results to improve the LLM's ability, which creates a self-improving AI feedback loop. While we acknowledge that AGI is a broad and multifaceted research challenge with no singularly defined solution path, the integration of LLMs with domain-specific expert models, inspired by mirroring the blend of general and specialized intelligence in humans, offers a promising approach towards AGI. We are open-sourcing the OpenAGI project's code, dataset, benchmarks, evaluation methods, and demo to foster community involvement in AGI advancement: https://github.com/agiresearch/OpenAGI.},
	author = {Ge, Yingqiang and Hua, Wenyue and Mei, Kai and Ji, Jianchao and Tan, Juntao and Xu, Shuyuan and Li, Zelong and Zhang, Yongfeng},
	date-added = {2023-07-05 11:30:28 +0200},
	date-modified = {2023-07-05 11:30:28 +0200},
	file = {Ge et al. - 2023 - OpenAGI When LLM Meets Domain Experts.pdf:/Users/maximilianslapnik/Zotero/storage/CNZMY6BX/Ge et al. - 2023 - OpenAGI When LLM Meets Domain Experts.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	language = {en},
	month = jun,
	note = {arXiv:2304.04370 [cs]},
	publisher = {arXiv},
	shorttitle = {{OpenAGI}},
	title = {{OpenAGI}: {When} {LLM} {Meets} {Domain} {Experts}},
	url = {http://arxiv.org/abs/2304.04370},
	urldate = {2023-07-05},
	year = {2023},
	bdsk-url-1 = {http://arxiv.org/abs/2304.04370}}

@inproceedings{zhu_be_2017,
	abstract = {We present a novel and effective approach for generating new clothing on a wearer through generative adversarial learning. Given an input image of a person and a sentence describing a different outfit, our model ``redresses'' the person as desired, while at the same time keeping the wearer and her/his pose unchanged. Generating new outfits with precise regions conforming to a language description while retaining wearer's body structure is a new challenging task. Existing generative adversarial networks are not ideal in ensuring global coherence of structure given both the input photograph and language description as conditions. We address this challenge by decomposing the complex generative process into two conditional stages. In the first stage, we generate a plausible semantic segmentation map that obeys the wearer's pose as a latent spatial arrangement. An effective spatial constraint is formulated to guide the generation of this semantic segmentation map. In the second stage, a generative model with a newly proposed compositional mapping layer is used to render the final image with precise regions and textures conditioned on this map. We extended the DeepFashion dataset [8] by collecting sentence descriptions for 79K images. We demonstrate the effectiveness of our approach through both quantitative and qualitative evaluations. A user study is also conducted.},
	address = {Venice},
	author = {Zhu, Shizhan and Fidler, Sanja and Urtasun, Raquel and Lin, Dahua and Loy, Chen Change},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	date-added = {2023-07-05 11:20:25 +0200},
	date-modified = {2023-07-05 11:20:25 +0200},
	doi = {10.1109/ICCV.2017.186},
	file = {Zhu et al. - 2017 - Be Your Own Prada Fashion Synthesis with Structur.pdf:/Users/maximilianslapnik/Zotero/storage/ZNFKNLL2/Zhu et al. - 2017 - Be Your Own Prada Fashion Synthesis with Structur.pdf:application/pdf},
	isbn = {978-1-5386-1032-9},
	language = {en},
	month = oct,
	pages = {1689--1697},
	publisher = {IEEE},
	shorttitle = {Be {Your} {Own} {Prada}},
	title = {Be {Your} {Own} {Prada}: {Fashion} {Synthesis} with {Structural} {Coherence}},
	url = {http://ieeexplore.ieee.org/document/8237448/},
	urldate = {2023-07-05},
	year = {2017},
	bdsk-url-1 = {http://ieeexplore.ieee.org/document/8237448/},
	bdsk-url-2 = {https://doi.org/10.1109/ICCV.2017.186}}

@misc{karras_progressive_2018,
	abstract = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 10242. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.},
	author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
	date-added = {2023-07-05 11:17:05 +0200},
	date-modified = {2023-07-05 11:17:05 +0200},
	file = {Karras et al. - 2018 - Progressive Growing of GANs for Improved Quality, .pdf:/Users/maximilianslapnik/Zotero/storage/IIK7E9MD/Karras et al. - 2018 - Progressive Growing of GANs for Improved Quality, .pdf:application/pdf},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	language = {en},
	month = feb,
	note = {arXiv:1710.10196 [cs, stat]},
	publisher = {arXiv},
	title = {Progressive {Growing} of {GANs} for {Improved} {Quality}, {Stability}, and {Variation}},
	url = {http://arxiv.org/abs/1710.10196},
	urldate = {2023-07-05},
	year = {2018},
	bdsk-url-1 = {http://arxiv.org/abs/1710.10196}}

@inproceedings{xu_attngan_2018,
	abstract = {In this paper, we propose an Attentional Generative Adversarial Network (AttnGAN) that allows attention-driven, multi-stage refinement for fine-grained text-to-image generation. With a novel attentional generative network, the AttnGAN can synthesize fine-grained details at different subregions of the image by paying attentions to the relevant words in the natural language description. In addition, a deep attentional multimodal similarity model is proposed to compute a fine-grained image-text matching loss for training the generator. The proposed AttnGAN significantly outperforms the previous state of the art, boosting the best reported inception score by 14.14\% on the CUB dataset and 170.25\% on the more challenging COCO dataset. A detailed analysis is also performed by visualizing the attention layers of the AttnGAN. It for the first time shows that the layered attentional GAN is able to automatically select the condition at the word level for generating different parts of the image.},
	address = {Salt Lake City, UT, USA},
	author = {Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	date-added = {2023-07-05 11:13:40 +0200},
	date-modified = {2023-07-05 11:13:40 +0200},
	doi = {10.1109/CVPR.2018.00143},
	file = {Xu et al. - 2018 - AttnGAN Fine-Grained Text to Image Generation wit.pdf:/Users/maximilianslapnik/Zotero/storage/SPFFDWVL/Xu et al. - 2018 - AttnGAN Fine-Grained Text to Image Generation wit.pdf:application/pdf},
	isbn = {978-1-5386-6420-9},
	language = {en},
	month = jun,
	pages = {1316--1324},
	publisher = {IEEE},
	shorttitle = {{AttnGAN}},
	title = {{AttnGAN}: {Fine}-{Grained} {Text} to {Image} {Generation} with {Attentional} {Generative} {Adversarial} {Networks}},
	url = {https://ieeexplore.ieee.org/document/8578241/},
	urldate = {2023-07-05},
	year = {2018},
	bdsk-url-1 = {https://ieeexplore.ieee.org/document/8578241/},
	bdsk-url-2 = {https://doi.org/10.1109/CVPR.2018.00143}}

@article{reed_generative_2016,
	abstract = {Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories, such as faces, album covers, and room interiors. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.},
	author = {Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
	date-added = {2023-07-05 10:31:00 +0200},
	date-modified = {2023-07-05 10:31:00 +0200},
	file = {Reed et al. - Generative Adversarial Text to Image Synthesis.pdf:/Users/maximilianslapnik/Zotero/storage/4QUPHZ7S/Reed et al. - Generative Adversarial Text to Image Synthesis.pdf:application/pdf},
	language = {en},
	title = {Generative {Adversarial} {Text} to {Image} {Synthesis}},
	year = {2016}}

@article{radford_language_2018,
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	date-added = {2023-07-05 10:28:20 +0200},
	date-modified = {2023-07-05 10:28:20 +0200},
	file = {Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:/Users/maximilianslapnik/Zotero/storage/D66I7HZ5/Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:application/pdf},
	language = {en},
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	year = {2018}}

@article{creswell_generative_2018,
	abstract = {Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data. They achieve this through deriving backpropagation signals through a competitive process involving a pair of networks. The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image super-resolution and classification. The aim of this review paper is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible. In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.},
	author = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
	date-added = {2023-07-05 10:20:45 +0200},
	date-modified = {2023-07-05 10:20:45 +0200},
	doi = {10.1109/MSP.2017.2765202},
	file = {Creswell et al. - 2018 - Generative Adversarial Networks An Overview.pdf:/Users/maximilianslapnik/Zotero/storage/4F27S4J3/Creswell et al. - 2018 - Generative Adversarial Networks An Overview.pdf:application/pdf},
	issn = {1053-5888},
	journal = {IEEE Signal Processing Magazine},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	language = {en},
	note = {arXiv:1710.07035 [cs]},
	number = {1},
	shorttitle = {Generative {Adversarial} {Networks}},
	title = {Generative {Adversarial} {Networks}: {An} {Overview}},
	url = {http://arxiv.org/abs/1710.07035},
	urldate = {2023-07-05},
	volume = {35},
	year = {2018},
	bdsk-url-1 = {http://arxiv.org/abs/1710.07035},
	bdsk-url-2 = {https://doi.org/10.1109/MSP.2017.2765202}}

@article{goodfellow_generative_2020,
	abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic highresolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	date-added = {2023-07-05 10:12:52 +0200},
	date-modified = {2023-07-05 10:12:52 +0200},
	doi = {10.1145/3422622},
	file = {Goodfellow et al. - 2020 - Generative adversarial networks.pdf:/Users/maximilianslapnik/Zotero/storage/YSW5C5Z6/Goodfellow et al. - 2020 - Generative adversarial networks.pdf:application/pdf},
	issn = {0001-0782, 1557-7317},
	journal = {Communications of the ACM},
	language = {en},
	month = oct,
	number = {11},
	pages = {139--144},
	title = {Generative adversarial networks},
	url = {https://dl.acm.org/doi/10.1145/3422622},
	urldate = {2023-07-05},
	volume = {63},
	year = {2020},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/3422622},
	bdsk-url-2 = {https://doi.org/10.1145/3422622}}

@article{goodfellow_generative_2014,
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	date-added = {2023-07-05 09:44:37 +0200},
	date-modified = {2023-07-05 09:44:37 +0200},
	file = {Goodfellow et al. - Generative Adversarial Nets.pdf:/Users/maximilianslapnik/Zotero/storage/VKJCEX54/Goodfellow et al. - Generative Adversarial Nets.pdf:application/pdf;NIPS-2014-generative-adversarial-nets-Bibtex.bib:/Users/maximilianslapnik/Zotero/storage/VZBNA3C3/NIPS-2014-generative-adversarial-nets-Bibtex.bib:application/x-bibtex},
	language = {en},
	title = {Generative {Adversarial} {Nets}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
	volume = {27},
	year = {2014},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}}

@misc{white_prompt_2023,
	abstract = {Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM.},
	author = {White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C.},
	date-added = {2023-06-13 21:47:50 +0200},
	date-modified = {2023-06-13 21:47:50 +0200},
	file = {White et al. - 2023 - A Prompt Pattern Catalog to Enhance Prompt Enginee.pdf:/Users/maximilianslapnik/Zotero/storage/QWS64YK9/White et al. - 2023 - A Prompt Pattern Catalog to Enhance Prompt Enginee.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	language = {en},
	month = feb,
	note = {arXiv:2302.11382 [cs]},
	publisher = {arXiv},
	title = {A {Prompt} {Pattern} {Catalog} to {Enhance} {Prompt} {Engineering} with {ChatGPT}},
	url = {http://arxiv.org/abs/2302.11382},
	urldate = {2023-05-18},
	year = {2023},
	bdsk-url-1 = {http://arxiv.org/abs/2302.11382}}

@misc{discord_discord_2023,
	author = {{Discord}},
	date-added = {2023-06-13 19:52:45 +0200},
	date-modified = {2023-06-13 19:52:45 +0200},
	file = {Discord | Your Place to Talk and Hang Out:/Users/maximilianslapnik/Zotero/storage/7YEZWUPC/discord.com.html:text/html},
	title = {Discord {\textbar} {Your} {Place} to {Talk} and {Hang} {Out}},
	url = {https://discord.com/},
	urldate = {2023-06-13},
	year = {2023},
	bdsk-url-1 = {https://discord.com/}}

@misc{midjourney_documentation_2023,
	author = {{Midjourney}},
	date-added = {2023-06-13 12:11:26 +0200},
	date-modified = {2023-06-13 12:11:26 +0200},
	file = {Midjourney Documentation and User Guide:/Users/maximilianslapnik/Zotero/storage/9T6D586H/docs.midjourney.com.html:text/html},
	title = {Documentation and {User} {Guide}},
	url = {https://docs.midjourney.com/},
	urldate = {2023-06-13},
	year = {2023},
	bdsk-url-1 = {https://docs.midjourney.com/}}

@misc{midjourney_midjourney_2023,
	author = {{Midjourney}},
	date-added = {2023-06-13 12:10:02 +0200},
	date-modified = {2023-06-13 12:10:02 +0200},
	file = {Midjourney:/Users/maximilianslapnik/Zotero/storage/63B6PZFF/home.html:text/html},
	title = {Midjourney},
	url = {https://www.midjourney.com/},
	urldate = {2023-06-13},
	year = {2023},
	bdsk-url-1 = {https://www.midjourney.com/}}

@article{rozado_political_2023,
	abstract = {Recent advancements in Large Language Models (LLMs) suggest imminent commercial applications of such AI systems where they will serve as gateways to interact with technology and the accumulated body of human knowledge. The possibility of political biases embedded in these models raises concerns about their potential misusage. In this work, we report the results of administering 15 different political orientation tests (14 in English, 1 in Spanish) to a state-of-the-art Large Language Model, the popular ChatGPT from OpenAI. The results are consistent across tests; 14 of the 15 instruments diagnose ChatGPT answers to their questions as manifesting a preference for left-leaning viewpoints. When asked explicitly about its political preferences, ChatGPT often claims to hold no political opinions and to just strive to provide factual and neutral information. It is desirable that public facing artificial intelligence systems provide accurate and factual information about empirically verifiable issues, but such systems should strive for political neutrality on largely normative questions for which there is no straightforward way to empirically validate a viewpoint. Thus, ethical AI systems should present users with balanced arguments on the issue at hand and avoid claiming neutrality while displaying clear signs of political bias in their content.},
	author = {Rozado, David},
	date-added = {2023-06-13 11:45:41 +0200},
	date-modified = {2023-06-13 11:45:41 +0200},
	doi = {10.3390/socsci12030148},
	file = {Rozado - 2023 - The Political Biases of ChatGPT.pdf:/Users/maximilianslapnik/Zotero/storage/V4P47SS8/Rozado - 2023 - The Political Biases of ChatGPT.pdf:application/pdf},
	issn = {2076-0760},
	journal = {Social Sciences},
	language = {en},
	month = mar,
	number = {3},
	pages = {148},
	title = {The {Political} {Biases} of {ChatGPT}},
	url = {https://www.mdpi.com/2076-0760/12/3/148},
	urldate = {2023-06-13},
	volume = {12},
	year = {2023},
	bdsk-url-1 = {https://www.mdpi.com/2076-0760/12/3/148},
	bdsk-url-2 = {https://doi.org/10.3390/socsci12030148}}

@article{van_bulck_what_2023,
	abstract = {Abstract
            ChatGPT is a new artificial intelligence system that revolutionizes the way how information can be sought and obtained. In this study, the trustworthiness, value, and danger of ChatGPT-generated responses on four vignettes that represented virtual patient questions were evaluated by 20 experts in the domain of congenital heart disease, atrial fibrillation, heart failure, or cholesterol. Experts generally considered ChatGPT-generated responses trustworthy and valuable, with few considering them dangerous. Forty percent of the experts found ChatGPT responses more valuable than Google. Experts appreciated the sophistication and nuances in the responses but also recognized that responses were often incomplete and sometimes misleading.},
	author = {Van Bulck, Liesbet and Moons, Philip},
	date-added = {2023-06-13 11:34:01 +0200},
	date-modified = {2023-06-13 11:34:01 +0200},
	doi = {10.1093/eurjcn/zvad038},
	file = {Van Bulck and Moons - 2023 - What if your patient switches from Dr. Google to D.pdf:/Users/maximilianslapnik/Zotero/storage/UTCRY3XY/Van Bulck and Moons - 2023 - What if your patient switches from Dr. Google to D.pdf:application/pdf},
	issn = {1474-5151, 1873-1953},
	journal = {European Journal of Cardiovascular Nursing},
	language = {en},
	month = apr,
	shorttitle = {What if your patient switches from {Dr}. {Google} to {Dr}. {ChatGPT}?},
	title = {What if your patient switches from {Dr}. {Google} to {Dr}. {ChatGPT}? {A} vignette-based survey of the trustworthiness, value, and danger of {ChatGPT}-generated responses to health questions},
	url = {https://academic.oup.com/eurjcn/advance-article/doi/10.1093/eurjcn/zvad038/7140165},
	urldate = {2023-06-13},
	year = {2023},
	bdsk-url-1 = {https://academic.oup.com/eurjcn/advance-article/doi/10.1093/eurjcn/zvad038/7140165},
	bdsk-url-2 = {https://doi.org/10.1093/eurjcn/zvad038}}

@misc{eshghie_chatgpt_2023,
	abstract = {This paper proposes using ChatGPT, an innovative technology with various applications, as an assistant for psychotherapy. ChatGPT can serve as a patient information collector, a companion for patients in between therapy sessions, and an organizer of gathered information for therapists to facilitate treatment processes. The research identifies five research questions and discovers useful prompts for fine-tuning the assistant, which shows that ChatGPT can participate in positive conversations, listen attentively, offer validation and potential coping strategies without providing explicit medical advice, and help therapists discover new insights from multiple conversations with the same patient. Using ChatGPT as an assistant for psychotherapy poses several challenges that need to be addressed, including technical as well as human-centric challenges which are discussed.},
	author = {Eshghie, Mahshid and Eshghie, Mojtaba},
	date-added = {2023-06-13 11:29:49 +0200},
	date-modified = {2023-06-13 11:29:49 +0200},
	file = {Eshghie and Eshghie - 2023 - ChatGPT as a Therapist Assistant A Suitability St.pdf:/Users/maximilianslapnik/Zotero/storage/M9YZDUNX/Eshghie and Eshghie - 2023 - ChatGPT as a Therapist Assistant A Suitability St.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
	language = {en},
	month = apr,
	note = {arXiv:2304.09873 [cs]},
	publisher = {arXiv},
	shorttitle = {{ChatGPT} as a {Therapist} {Assistant}},
	title = {{ChatGPT} as a {Therapist} {Assistant}: {A} {Suitability} {Study}},
	url = {http://arxiv.org/abs/2304.09873},
	urldate = {2023-06-13},
	year = {2023},
	bdsk-url-1 = {http://arxiv.org/abs/2304.09873}}

@misc{google_google_2023,
	author = {{Google}},
	date-added = {2023-06-06 19:29:48 +0200},
	date-modified = {2023-06-06 19:29:48 +0200},
	file = {Google:/Users/maximilianslapnik/Zotero/storage/5UPVE9D7/www.google.com.html:text/html},
	title = {Google},
	url = {https://www.google.com/},
	urldate = {2023-06-01},
	year = {2023},
	bdsk-url-1 = {https://www.google.com/}}

@misc{statista_us_2022,
	author = {{Statista}},
	date-added = {2023-06-06 19:28:36 +0200},
	date-modified = {2023-06-06 19:28:36 +0200},
	file = {Screenshot 2023-06-06 at 15.28.16.png:/Users/maximilianslapnik/Zotero/storage/DZERSG9V/Screenshot 2023-06-06 at 15.28.16.png:image/png;U.S.\: generative AI adoption rate in the workplace by generation 2023 | Statista:/Users/maximilianslapnik/Zotero/storage/ST2VXABG/generative-ai-adoption-rate-at-work-by-generation-us.html:text/html},
	month = dec,
	title = {U.{S}.: generative {AI} adoption rate in the workplace by generation 2023},
	url = {https://www.statista.com/statistics/1361174/generative-ai-adoption-rate-at-work-by-generation-us/},
	urldate = {2023-06-06},
	year = {2022},
	bdsk-url-1 = {https://www.statista.com/statistics/1361174/generative-ai-adoption-rate-at-work-by-generation-us/}}

@misc{statista_artificial_2023,
	author = {{Statista}},
	date-added = {2023-06-06 19:28:06 +0200},
	date-modified = {2023-06-06 19:28:06 +0200},
	file = {Artificial Intelligence market size 2030 | Statista:/Users/maximilianslapnik/Zotero/storage/JQXX4XX3/artificial-intelligence-market-size.html:text/html;Screenshot 2023-06-06 at 15.29.12.png:/Users/maximilianslapnik/Zotero/storage/U5FQ4BX5/Screenshot 2023-06-06 at 15.29.12.png:image/png},
	month = jan,
	title = {Artificial {Intelligence} market size 2030},
	url = {https://www.statista.com/statistics/1365145/artificial-intelligence-market-size/},
	urldate = {2023-06-06},
	year = {2023},
	bdsk-url-1 = {https://www.statista.com/statistics/1365145/artificial-intelligence-market-size/}}

@misc{sharegpt_sharegpt_2023,
	author = {{ShareGPT}},
	date-added = {2023-06-06 17:50:56 +0200},
	date-modified = {2023-06-06 17:50:56 +0200},
	file = {ShareGPT\: Share your wildest ChatGPT conversations with one click.:/Users/maximilianslapnik/Zotero/storage/SVDN6BTH/sharegpt.com.html:text/html},
	title = {{ShareGPT}: {Share} your wildest {ChatGPT} conversations with one click.},
	url = {https://sharegpt.com/},
	urldate = {2023-06-06},
	year = {2023},
	bdsk-url-1 = {https://sharegpt.com/}}

@misc{dang_how_2022,
	abstract = {Deep generative models have the potential to fundamentally change the way we create high-fidelity digital content but are often hard to control. Prompting a generative model is a promising recent development that in principle enables end-users to creatively leverage zero-shot and few-shot learning to assign new tasks to an AI adhoc, simply by writing them down. However, for the majority of end-users writing effective prompts is currently largely a trial and error process. To address this, we discuss the key opportunities and challenges for interactive creative applications that use prompting as a new paradigm for Human-AI interaction. Based on our analysis, we propose four design goals for user interfaces that support prompting. We illustrate these with concrete UI design sketches, focusing on the use case of creative writing. The research community in HCI and AI can take these as starting points to develop adequate user interfaces for models capable of zero- and few-shot learning.},
	author = {Dang, Hai and Mecke, Lukas and Lehmann, Florian and Goller, Sven and Buschek, Daniel},
	date-added = {2023-06-05 15:40:37 +0200},
	date-modified = {2023-06-05 15:40:37 +0200},
	file = {Dang et al. - 2022 - How to Prompt Opportunities and Challenges of Zer.pdf:/Users/maximilianslapnik/Zotero/storage/5GAGBIJM/Dang et al. - 2022 - How to Prompt Opportunities and Challenges of Zer.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, H.5.2, I.2.7},
	language = {en},
	month = sep,
	note = {arXiv:2209.01390 [cs]},
	publisher = {arXiv},
	shorttitle = {How to {Prompt}?},
	title = {How to {Prompt}? {Opportunities} and {Challenges} of {Zero}- and {Few}-{Shot} {Learning} for {Human}-{AI} {Interaction} in {Creative} {Applications} of {Generative} {Models}},
	url = {http://arxiv.org/abs/2209.01390},
	urldate = {2023-05-18},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2209.01390}}

@inproceedings{zamfirescu-pereira_why_2023,
	abstract = {Pre-trained large language models (``LLMs'') like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (``prompting'') has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in ``end-user prompt engineering'' using a design probe---a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.},
	address = {Hamburg Germany},
	author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	date-added = {2023-06-02 14:38:42 +0200},
	date-modified = {2023-06-02 14:38:42 +0200},
	doi = {10.1145/3544548.3581388},
	file = {Zamfirescu-Pereira et al. - 2023 - Why Johnny Can't Prompt How Non-AI Experts Try (a.pdf:/Users/maximilianslapnik/Zotero/storage/3TKEAAZU/Zamfirescu-Pereira et al. - 2023 - Why Johnny Can't Prompt How Non-AI Experts Try (a.pdf:application/pdf},
	isbn = {978-1-4503-9421-5},
	language = {en},
	month = apr,
	pages = {1--21},
	publisher = {ACM},
	shorttitle = {Why {Johnny} {Can}'t {Prompt}},
	title = {Why {Johnny} {Can}'t {Prompt}: {How} {Non}-{AI} {Experts} {Try} (and {Fail}) to {Design} {LLM} {Prompts}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581388},
	urldate = {2023-05-18},
	year = {2023},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/3544548.3581388},
	bdsk-url-2 = {https://doi.org/10.1145/3544548.3581388}}

@misc{microsoft_bing_2023,
	author = {{Microsoft}},
	date-added = {2023-06-01 10:14:10 +0200},
	date-modified = {2023-06-01 10:14:10 +0200},
	file = {Bing:/Users/maximilianslapnik/Zotero/storage/GZN2U8AF/www.bing.com.html:text/html},
	title = {Bing},
	url = {https://www.bing.com/?cc=de},
	urldate = {2023-06-01},
	year = {2023},
	bdsk-url-1 = {https://www.bing.com/?cc=de}}

@inproceedings{huang_analyzing_2009,
	abstract = {Users frequently modify a previous search query in hope of retrieving better results. These modifications are called query reformulations or query refinements. Existing research has studied how web search engines can propose reformulations, but has given less attention to how people perform query reformulations. In this paper, we aim to better understand how web searchers refine queries and form a theoretical foundation for query reformulation. We study users' reformulation strategies in the context of the AOL query logs. We create a taxonomy of query refinement strategies and build a high precision rule-based classifier to detect each type of reformulation. Effectiveness of reformulations is measured using user click behavior. Most reformulation strategies result in some benefit to the user. Certain strategies like add/remove words, word substitution, acronym expansion, and spelling correction are more likely to cause clicks, especially on higher ranked results. In contrast, users often click the same result as their previous query or select no results when forming acronyms and reordering words. Perhaps the most surprising finding is that some reformulations are better suited to helping users when the current results are already fruitful, while other reformulations are more effective when the results are lacking. Our findings inform the design of applications that can assist searchers; examples are described in this paper.},
	address = {Hong Kong China},
	author = {Huang, Jeff and Efthimiadis, Efthimis N.},
	booktitle = {Proceedings of the 18th {ACM} conference on {Information} and knowledge management},
	date-added = {2023-05-31 18:31:12 +0200},
	date-modified = {2023-05-31 18:31:12 +0200},
	doi = {10.1145/1645953.1645966},
	file = {Huang and Efthimiadis - 2009 - Analyzing and evaluating query reformulation strat.pdf:/Users/maximilianslapnik/Zotero/storage/HRQVVN48/Huang and Efthimiadis - 2009 - Analyzing and evaluating query reformulation strat.pdf:application/pdf},
	isbn = {978-1-60558-512-3},
	language = {en},
	month = nov,
	pages = {77--86},
	publisher = {ACM},
	title = {Analyzing and evaluating query reformulation strategies in web search logs},
	url = {https://dl.acm.org/doi/10.1145/1645953.1645966},
	urldate = {2023-05-18},
	year = {2009},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/1645953.1645966},
	bdsk-url-2 = {https://doi.org/10.1145/1645953.1645966}}

@misc{dairai_few-shot_2023,
	author = {{DAIR.AI}},
	date-added = {2023-05-27 08:50:42 +0200},
	date-modified = {2023-05-27 08:50:42 +0200},
	file = {Few-Shot Prompting Prompt Engineering Guide!-- .pdf:/Users/maximilianslapnik/Zotero/storage/7UQQGM9L/Few-Shot Prompting Prompt Engineering Guide!-- .pdf:application/pdf;Few-Shot Prompting | Prompt Engineering Guide<!-- -->:/Users/maximilianslapnik/Zotero/storage/5NC42LJK/fewshot.html:text/html},
	title = {Few-{Shot} {Prompting} {\textbar} {Prompt} {Engineering} {Guide}},
	url = {https://www.promptingguide.ai/techniques/fewshot},
	urldate = {2023-05-27},
	year = {2023},
	bdsk-url-1 = {https://www.promptingguide.ai/techniques/fewshot}}

@misc{brown_language_2020,
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions -- something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art finetuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	date-added = {2023-05-27 08:14:34 +0200},
	date-modified = {2023-05-27 08:14:34 +0200},
	file = {Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:/Users/maximilianslapnik/Zotero/storage/UMFG7ESD/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language},
	language = {en},
	month = jul,
	note = {arXiv:2005.14165 [cs]},
	publisher = {arXiv},
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	urldate = {2023-05-27},
	year = {2020},
	bdsk-url-1 = {http://arxiv.org/abs/2005.14165}}

@misc{samuel_offline_2022,
	abstract = {Few-shot learning is an important, but challenging problem of machine learning aimed at learning from only fewer labeled training examples. It has become an active area of research due to deep learning requiring huge amounts of labeled dataset, which is not feasible in the real world. Learning from a few examples is also an important attempt towards learning like humans. Few-shot learning has proven a very good promise in different areas of machine learning applications, particularly in image classification. As it is a recent technique, most researchers focus on understanding and solving the issues related to its concept by focusing only on common image datasets like Mini-ImageNet and Omniglot. Few-shot learning also opens an opportunity to address low resource languages like Amharic. In this study, offline handwritten Amharic character recognition using few-shot learning is addressed. Particularly, prototypical networks, the popular and simpler type of fewshot learning, is implemented as a baseline. Using the opportunities explored in the nature of Amharic alphabet having row-wise and columnwise similarities, a novel way of augmenting the training episodes is proposed. The experimental results show that the proposed method outperformed the baseline method. This study has implemented few-shot learning for Amharic characters for the first time. More importantly, the findings of the study open new ways of examining the influence of training episodes in few-shot learning, which is one of the important issues that needs exploration. The datasets used for this study are collected from native Amharic language writers using an Android App developed as a part of this study.},
	author = {Samuel, Mesay and Schmidt-Thieme, Lars and Sharma, D. P. and Sinamo, Abiot and Bruck, Abey},
	date-added = {2023-05-27 07:37:03 +0200},
	date-modified = {2023-05-27 07:37:03 +0200},
	file = {Samuel et al. - 2022 - Offline Handwritten Amharic Character Recognition .pdf:/Users/maximilianslapnik/Zotero/storage/89MEREMV/Samuel et al. - 2022 - Offline Handwritten Amharic Character Recognition .pdf:application/pdf},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	language = {en},
	month = oct,
	note = {arXiv:2210.00275 [cs]},
	publisher = {arXiv},
	title = {Offline {Handwritten} {Amharic} {Character} {Recognition} {Using} {Few}-shot {Learning}},
	url = {http://arxiv.org/abs/2210.00275},
	urldate = {2023-05-27},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA6Li4vLi4vLi4vLi4vLi4vLi4vLi4vLi4vLi4vLi4vRG93bmxvYWRzL0V4cG9ydGVkIEl0ZW1zLmJpYk8RAW4AAAAAAW4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAOBOLJpCRAAB/////xJFeHBvcnRlZCBJdGVtcy5iaWIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4JPwUgAAAAAAAAAAAAoAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACADYvOlVzZXJzOm1heGltaWxpYW5zbGFwbmlrOkRvd25sb2FkczpFeHBvcnRlZCBJdGVtcy5iaWIADgAmABIARQB4AHAAbwByAHQAZQBkACAASQB0AGUAbQBzAC4AYgBpAGIADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA0VXNlcnMvbWF4aW1pbGlhbnNsYXBuaWsvRG93bmxvYWRzL0V4cG9ydGVkIEl0ZW1zLmJpYgATAAEvAAAVAAIAGP//AAAACAANABoAJABhAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAdM=},
	bdsk-url-1 = {http://arxiv.org/abs/2210.00275}}

@incollection{feris_embarrassingly_2015,
	abstract = {Zero-shot learning consists in learning how to recognise new concepts by just having a description of them. Many sophisticated approaches have been proposed to address the challenges this problem comprises. In this paper we describe a zero-shot learning approach that can be implemented in just one line of code, yet it is able to outperform state of the art approaches on standard datasets. The approach is based on a more general framework which models the relationships between features, attributes, and classes as a two linear layers network, where the weights of the top layer are not learned but are given by the environment. We further provide a learning bound on the generalisation error of this kind of approaches, by casting them as domain adaptation methods. In experiments carried out on three standard real datasets, we found that our approach is able to perform significantly better than the state of art on all of them, obtaining a ratio of improvement up to 17\%.},
	author = {Romera-Paredes, Bernardino and Torr, Philip H. S.},
	date-added = {2023-05-25 21:15:19 +0200},
	date-modified = {2023-05-25 21:15:19 +0200},
	doi = {10.1007/978-3-319-50077-5_2},
	editor = {Feris, Rogerio Schmidt and Lampert, Christoph and Parikh, Devi},
	file = {Romera-Paredes and Torr - 2017 - An Embarrassingly Simple Approach to Zero-Shot Lea.pdf:/Users/maximilianslapnik/Zotero/storage/JZKMIAID/Romera-Paredes and Torr - 2017 - An Embarrassingly Simple Approach to Zero-Shot Lea.pdf:application/pdf},
	isbn = {978-3-319-50075-1 978-3-319-50077-5},
	language = {en},
	note = {Series Title: Advances in Computer Vision and Pattern Recognition},
	title = {An {Embarrassingly} {Simple} {Approach} to {Zero}-{Shot} {Learning}},
	url = {http://link.springer.com/10.1007/978-3-319-50077-5_2},
	urldate = {2023-05-25},
	year = {2015},
	bdsk-url-1 = {http://link.springer.com/10.1007/978-3-319-50077-5_2},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-50077-5_2}}

@misc{shuster_blenderbot_2022,
	abstract = {We present BlenderBot 3, a 175B parameter dialogue model capable of open-domain conversation with access to the internet and a longterm memory, and having been trained on a large number of user defined tasks. We release both the model weights and code, and have also deployed the model on a public web page to interact with organic users. This technical report describes how the model was built (architecture, model and training scheme), and details of its deployment, including safety mechanisms. Human evaluations show its superiority to existing open-domain dialogue agents, including its predecessors (Roller et al., 2021; Komeili et al., 2022). Finally, we detail our plan for continual learning using the data collected from deployment, which will also be publicly released. The goal of this research program is thus to enable the community to study ever-improving responsible agents that learn through interaction.},
	author = {Shuster, Kurt and Xu, Jing and Komeili, Mojtaba and Ju, Da and Smith, Eric Michael and Roller, Stephen and Ung, Megan and Chen, Moya and Arora, Kushal and Lane, Joshua and Behrooz, Morteza and Ngan, William and Poff, Spencer and Goyal, Naman and Szlam, Arthur and Boureau, Y.-Lan and Kambadur, Melanie and Weston, Jason},
	date-added = {2023-05-24 19:01:50 +0200},
	date-modified = {2023-05-24 19:01:50 +0200},
	file = {Shuster et al. - 2022 - BlenderBot 3 a deployed conversational agent that.pdf:/Users/maximilianslapnik/Zotero/storage/DIDB6ZFQ/Shuster et al. - 2022 - BlenderBot 3 a deployed conversational agent that.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	language = {en},
	month = aug,
	note = {arXiv:2208.03188 [cs]},
	publisher = {arXiv},
	shorttitle = {{BlenderBot} 3},
	title = {{BlenderBot} 3: a deployed conversational agent that continually learns to responsibly engage},
	url = {http://arxiv.org/abs/2208.03188},
	urldate = {2023-05-24},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2208.03188}}

@misc{glaese_improving_2022,
	abstract = {We present Sparrow, an information-seeking dialogue agent trained to be more helpful, correct, and harmless compared to prompted language model baselines. We use reinforcement learning from human feedback to train our models with two new additions to help human raters judge agent behaviour. First, to make our agent more helpful and harmless, we break down the requirements for good dialogue into natural language rules the agent should follow, and ask raters about each rule separately. We demonstrate that this breakdown enables us to collect more targeted human judgements of agent behaviour and allows for more efficient rule-conditional reward models. Second, our agent provides evidence from sources supporting factual claims when collecting preference judgements over model statements. For factual questions, evidence provided by Sparrow supports the sampled response 78\% of the time. Sparrow is preferred more often than baselines while being more resilient to adversarial probing by humans, violating our rules only 8\% of the time when probed. Finally, we conduct extensive analyses showing that though our model learns to follow our rules it can exhibit distributional biases.},
	author = {Glaese, Amelia and McAleese, Nat and Tr{\k e}bacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and Campbell-Gillingham, Lucy and Uesato, Jonathan and Huang, Po-Sen and Comanescu, Ramona and Yang, Fan and See, Abigail and Dathathri, Sumanth and Greig, Rory and Chen, Charlie and Fritz, Doug and Elias, Jaume Sanchez and Green, Richard and Mokr{\'a}, So{\v n}a and Fernando, Nicholas and Wu, Boxi and Foley, Rachel and Young, Susannah and Gabriel, Iason and Isaac, William and Mellor, John and Hassabis, Demis and Kavukcuoglu, Koray and Hendricks, Lisa Anne and Irving, Geoffrey},
	date-added = {2023-05-24 18:59:55 +0200},
	date-modified = {2023-05-24 18:59:55 +0200},
	file = {Glaese et al. - 2022 - Improving alignment of dialogue agents via targete.pdf:/Users/maximilianslapnik/Zotero/storage/AK7V6HH5/Glaese et al. - 2022 - Improving alignment of dialogue agents via targete.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	language = {en},
	month = sep,
	note = {arXiv:2209.14375 [cs]},
	publisher = {arXiv},
	title = {Improving alignment of dialogue agents via targeted human judgements},
	url = {http://arxiv.org/abs/2209.14375},
	urldate = {2023-05-24},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2209.14375}}

@misc{thoppilan_lamda_2022,
	abstract = {We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformerbased neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency.},
	author = {Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and Li, YaGuang and Lee, Hongrae and Zheng, Huaixiu Steven and Ghafouri, Amin and Menegali, Marcelo and Huang, Yanping and Krikun, Maxim and Lepikhin, Dmitry and Qin, James and Chen, Dehao and Xu, Yuanzhong and Chen, Zhifeng and Roberts, Adam and Bosma, Maarten and Zhao, Vincent and Zhou, Yanqi and Chang, Chung-Ching and Krivokon, Igor and Rusch, Will and Pickett, Marc and Srinivasan, Pranesh and Man, Laichee and Meier-Hellstern, Kathleen and Morris, Meredith Ringel and Doshi, Tulsee and Santos, Renelito Delos and Duke, Toju and Soraker, Johnny and Zevenbergen, Ben and Prabhakaran, Vinodkumar and Diaz, Mark and Hutchinson, Ben and Olson, Kristen and Molina, Alejandra and Hoffman-John, Erin and Lee, Josh and Aroyo, Lora and Rajakumar, Ravi and Butryna, Alena and Lamm, Matthew and Kuzmina, Viktoriya and Fenton, Joe and Cohen, Aaron and Bernstein, Rachel and Kurzweil, Ray and Aguera-Arcas, Blaise and Cui, Claire and Croak, Marian and Chi, Ed and Le, Quoc},
	date-added = {2023-05-24 18:50:43 +0200},
	date-modified = {2023-05-24 18:50:43 +0200},
	file = {Thoppilan et al. - 2022 - LaMDA Language Models for Dialog Applications.pdf:/Users/maximilianslapnik/Zotero/storage/PD4FXT6T/Thoppilan et al. - 2022 - LaMDA Language Models for Dialog Applications.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	language = {en},
	month = feb,
	note = {arXiv:2201.08239 [cs]},
	publisher = {arXiv},
	shorttitle = {{LaMDA}},
	title = {{LaMDA}: {Language} {Models} for {Dialog} {Applications}},
	url = {http://arxiv.org/abs/2201.08239},
	urldate = {2023-05-24},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA6Li4vLi4vLi4vLi4vLi4vLi4vLi4vLi4vLi4vLi4vRG93bmxvYWRzL0V4cG9ydGVkIEl0ZW1zLmJpYk8RAW4AAAAAAW4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAOBOLJpCRAAB/////xJFeHBvcnRlZCBJdGVtcy5iaWIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4JPwUgAAAAAAAAAAAAoAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACADYvOlVzZXJzOm1heGltaWxpYW5zbGFwbmlrOkRvd25sb2FkczpFeHBvcnRlZCBJdGVtcy5iaWIADgAmABIARQB4AHAAbwByAHQAZQBkACAASQB0AGUAbQBzAC4AYgBpAGIADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA0VXNlcnMvbWF4aW1pbGlhbnNsYXBuaWsvRG93bmxvYWRzL0V4cG9ydGVkIEl0ZW1zLmJpYgATAAEvAAAVAAIAGP//AAAACAANABoAJABhAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAdM=},
	bdsk-url-1 = {http://arxiv.org/abs/2201.08239}}

@article{radford_improving_2018,
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	date-added = {2023-05-24 18:28:22 +0200},
	date-modified = {2023-05-24 18:28:22 +0200},
	file = {Radford et al. - Improving Language Understanding by Generative Pre.pdf:/Users/maximilianslapnik/Zotero/storage/BNIVP4RK/Radford et al. - Improving Language Understanding by Generative Pre.pdf:application/pdf},
	language = {en},
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	year = {2018}}

@article{vaswani_attention_2017,
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	date-added = {2023-05-24 18:15:01 +0200},
	date-modified = {2023-05-24 18:15:01 +0200},
	file = {Vaswani et al. - Attention is All you Need.pdf:/Users/maximilianslapnik/Zotero/storage/S7NUJBLF/Vaswani et al. - Attention is All you Need.pdf:application/pdf},
	language = {en},
	title = {Attention is {All} you {Need}},
	volume = {30},
	year = {2017}}

@inproceedings{lee_coauthor_2022,
	abstract = {Large language models (LMs) ofer unprecedented language generation capabilities and exciting opportunities for interaction design. However, their highly context-dependent capabilities are difcult to grasp and are often subjectively interpreted. In this paper, we argue that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs' generative capabilities. Exemplifying this approach, we present CoAuthor, a dataset designed for revealing GPT-3's capabilities in assisting creative and argumentative writing. CoAuthor captures rich interactions between 63 writers and four instances of GPT-3 across 1445 writing sessions. We demonstrate that CoAuthor can address questions about GPT-3's language, ideation, and collaboration capabilities, and reveal its contribution as a writing ``collaborator'' under various defnitions of good collaboration. Finally, we discuss how this work may facilitate a more principled discussion around LMs' promises and pitfalls in relation to interaction design. The dataset and an interface for replaying the writing sessions are publicly available at https://coauthor.stanford.edu.},
	address = {New Orleans LA USA},
	author = {Lee, Mina and Liang, Percy and Yang, Qian},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	date-added = {2023-05-24 17:09:00 +0200},
	date-modified = {2023-05-24 17:09:00 +0200},
	doi = {10.1145/3491102.3502030},
	file = {Lee et al. - 2022 - CoAuthor Designing a Human-AI Collaborative Writi.pdf:/Users/maximilianslapnik/Zotero/storage/B58HKHBC/Lee et al. - 2022 - CoAuthor Designing a Human-AI Collaborative Writi.pdf:application/pdf},
	isbn = {978-1-4503-9157-3},
	language = {en},
	month = apr,
	pages = {1--19},
	publisher = {ACM},
	shorttitle = {{CoAuthor}},
	title = {{CoAuthor}: {Designing} a {Human}-{AI} {Collaborative} {Writing} {Dataset} for {Exploring} {Language} {Model} {Capabilities}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3502030},
	urldate = {2023-05-18},
	year = {2022},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/3491102.3502030},
	bdsk-url-2 = {https://doi.org/10.1145/3491102.3502030}}

@misc{openai_chatgpt_2023,
	author = {{OpenAI}},
	date-added = {2023-05-24 16:48:23 +0200},
	date-modified = {2023-05-24 16:48:23 +0200},
	file = {ChatGPT | OpenAI:/Users/maximilianslapnik/Zotero/storage/SNJ44DY6/login.html:text/html},
	title = {{ChatGPT}},
	url = {https://chat.openai.com/auth/login},
	urldate = {2023-05-24},
	year = {2023},
	bdsk-url-1 = {https://chat.openai.com/auth/login}}
