%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% STUDY ON USAGE PATTERNS OF LLM USERS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Study on Usage Patterns of LLM Users}
\label{sec:study-on-usage-patterns-of-llm-users}

% Ideas for language prompt coding categories:
%- Prompt type: could include questions, statements, commands, or specific task-based prompts
%- User intent: could include seeking information, asking for advice, requesting clarification,
% expressing opinions, or making suggestions
%- Response quality: might include accurate and helpful responses, incomplete or ambiguous
% responses, irrelevant responses, or responses requiring further clarification
%- User satisfaction: could include satisfied, dissatisfied, neutral, confused, or impressed
%- Engagement level: might include active conversation, single-turn interactions, probing for
% more information, or exploratory questioning
%- Task success: could include successful completion, partial success, or failure
%- Response length
%- Ethical considerations: might include potential biases in the generated responses, adherence
% to ethical guidelines, or fairness and inclusivity in the LLM's behavior

% % Ideas for image prompt coding categories:
% Prompt type: capture the types of inputs users provide to the image generation models
% User intent: Extend the user intent category to encompass image-related intents--could
% include users requesting image generation, describing desired visual characteristics, or
% seeking specific visual outcomes.
% Response quality: evaluate the quality of the generated images--consider aspects such as visual
% fidelity, realism, relevance to the user's request, or adherence to given guidelines.
% User satisfaction: not possible? maybe on discord (but hard to discern)
% Engagement level: might involve exploring how users refine their requests, provide feedback on
% generated images, or iteratively interact with the model to achieve their desired visual
% outcomes. (hard to discern, same as above)
% Task success: might include successful image generation, partially successful
% results, or cases where the model failed to meet the user's expectations.
% Ethical considerations: could involve examining issues such as biases in generated images,
% ethical implications of content creation, privacy concerns related to user-provided images, or
% responsible use of image generation models.

% analysis: do we see differences between text and image prompts? which is more successful /
% accurate in general? do we observe sentiment differences?

% Analyze distribution of zero-, one-, and few-shot prompts
% analyze frequency of prompt reformulations in order to improve results
%

\subsection{Research Objective}
\label{subsec:research-objective}
% Intro and Research Objective of the study goal, the methodology, and the individual
% steps that will be taken
The main outlined goal of our research to gain a fundamental understanding of user
interaction in conversation with Large Language Models.
This analysis includes identifying common patterns and strategies in those interactions.
Previous research indicates, that users regularly face challenges and difficulties, especially
when trying to formulate effective prompts.
Through analysis of qualified data samples we aim to identify and understand these
challenges,
as well as investigate the impact and effect of user behavior on the effectiveness of LLM responses.
Given the various kinds of available generative models, we want to examine differences in
prompting behavior according to model type as well.

Since related insights suggest that reformulating search queries is a popular strategy to improve
results, we want to investigate if users apply this strategy in LLM conversations as well. % TODO
% check if we really did this
Furthermore, we want to assess extent to which users show awareness of effective prompt
formulation strategies, such as few-shot learning, and whether they rely on appropriate language
that is machine and not human directed, thus showing comprehension of the fundamental difference
between talking to a machine versus a human.

\subsection{Research Method: ShareGPT and Midjourney}
\label{subsec:research-method:-sharegpt-and-midjourney}
% Information on the ShareGPT & Midjourney platforms, their user base, suitability for the
% study, and which data we are going to use
In order to obtain credible insights, we complement existing findings with real-world data.
Our study analyzes data samples from two different sources, which involve different types of
LLMs.
First, we examine user interactions with ChatGPT, a generative NLP model.
These conversations were obtained from the website ShareGPT\cite{sharegpt_sharegpt_2023}.
ShareGPT is an open platform, that allows its community to publicly share conversations they have
had with the ChatGPT model.
As of today, ShareGPT has accumulated nearly 300.000 saved user conversations.
What makes ShareGPT particularly suitable for our use-case is the fact that the entire shared conversation
can then be viewed by the observer as if they had personally conducted the interaction.
This feature allows us to gain a deeper understanding of the conversation dynamics and
outcome.
By randomly choosing 50 conversations from ShareGPT, we obtain a representative sample of average
user interactions.
\newline

Midjourney in contrast, is a platform that focuses on AI-based image generation instead of text.
Users can interact with the model through Discord and submit individual prompts. % TODO cite Discord
In order to generate an illustration, a user has to enter a descriptive prompt, similar to
ChatGPT\@.
The description is usually comprised of everything that should appear in the picture, but may also
include the desired mood, drawing style, or composition of the image being generated.
Notably, the Midjourney Bot does not understand grammar, sentence structure, or specific words like
humans. % TODO cite
The developers actively encourage using fewer, but more precise and impactful words when prompting
the model.
For example, they suggest using \("\)gigantic\("\) instead of \("\)big\("\) in order to achieve
better results. %TODO cite
This recommendation stems from the fact that fewer words in a prompt intensify the influence each
individual word has on the final outcome.
However, % Be specific: anything you leave out will be randomized
Finally, Midjourney allows image inputs in addition to textual prompts.
Users may provide an image including instructions about things to modify, add, remove, or remodel.



% TODO section or subsection?


\section{Study Results}
\label{sec:study-results}

\subsection{}
% Listing of the results of the study, potentially segregated into categories that can be defined
% in advance

% TODO make an own subsection on difficulties of ordinary users in understanding how LLMs interpret
% natural language? in this subsec, we could focus on the example also displayed on midjourneys
% website: " If you ask for a party with “no cake,” your image will probably include a cake"
