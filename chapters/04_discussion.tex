%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DISCUSSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
\label{sec:discussion}
% 1. Why do users interact with LLMs the way they do? Reasoning and informed assumptions on the
% causes of observed behavior
% 2. Prompt Improvement Possibilities Proposition of ways to enhance prompts as well as associated
% results based on findings from related researc

% first ChatGPT, then Midjourney analysis, then comparison?

\subsection{Data Synthesis: Commonalities, Differences, and Possible Explanations}
\label{subsec:data-synthesis:-commonalities-differences-and-possible-explanations}
In this section, we reason about the observed behavior from the two data sources and try to offer
informed assumptions on potential causes.

\subsubsection{ChatGPT Behavior}
In regard to the type of prompt, we observed mainly task-based and question-related queries from
users.
This leads us to imagine that some users treat LLMs such as ChatGPT increasingly as their
personal online assistant when it comes to executing various tasks the model might be able to solve.
Leveraging AI bots as assistants of the future is a use case that gains popularity, and that is also
increasingly researched~\cite{eshghie_chatgpt_2023}.
The second most prevalent type of prompt were questions.
We have already mentioned, that NLP models might replace current search engines in the future.
This belief is further confirmed by observations from other researches who already see this
emerging trend in user behavior~\cite{van_bulck_what_2023}.
Regarding prompt intent, looking for information was the most popular use case.
Seemingly, users see ChatGPT as a reliable source of knowledge and trust its abilities.
This assumption can be dangerous however, as it is well-known that every LLM is probabilistic and
only as good as its training data.
Results should therefore always be verified.
Based on the fact that a lot of users also relied on ChatGPT for suggestions, we assume that it
is gladly used as a means to get ahead when you hit roadblocks, or need support in endeavours
that require creativity.
As we already touched on above, we did not have any requests for opinions of the model.
We would have thought that opinion related requests on difficult, morally complex, or
controversial topics would be more popular, since such behavior could be observed a lot online when
users tried to test the limits of the model, or for example when researchers tested political
biases~\cite{rozado_political_2023}.
Regarding the prompt setting, we made an observation similar to Brown et al.~\cite{
    brown_language_2020}.
Users do not leverage effective prompting techniques such as a few-shot approach.
Instead, they relied heavily (90\%) on zero shot prompts.
We attribute this behavior to missing awareness of users about optimized techniques, and
therefore recommend that LLM providers actively make users actively inform users, e.g. by
providing examples, or releasing guidelines.
Our observations when looking at user engagement makes us think that current LLMs are already
quite accurate: almost half of the users finished the conversation after the initial answer of
the LLM (single turn).
This is further reinforced by 66\% of prompts that were not refined.
We therefore suspect, that most of the time the users were actually content with the results.
However, we have to mention the possibility that the initial answer was so far off,
that users might have stopped trying after the first attempt.
Overall, we reckon that users prefer to leverage LLMs for rather simple tasks.
It is difficult to say, whether users do not trust LLMs enough to throw complex questions at
them yet, or if it simply is in the nature of online search requests, that the majority of search
requests that users look up are more of a simple nature than very complex.


\subsubsection{Midjourney Behavior}

\subsubsection{Commonalities and Differences between ChatGPT and Midjourney}
