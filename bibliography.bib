%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Maximilian Slapnik at 2023-05-27 08:14:37 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@misc{brown_language_2020,
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions -- something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art finetuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	date-added = {2023-05-27 08:14:34 +0200},
	date-modified = {2023-05-27 08:14:34 +0200},
	file = {Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:/Users/maximilianslapnik/Zotero/storage/UMFG7ESD/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language},
	language = {en},
	month = jul,
	note = {arXiv:2005.14165 [cs]},
	publisher = {arXiv},
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	urldate = {2023-05-27},
	year = {2020},
	bdsk-url-1 = {http://arxiv.org/abs/2005.14165}}

@misc{samuel_offline_2022,
	abstract = {Few-shot learning is an important, but challenging problem of machine learning aimed at learning from only fewer labeled training examples. It has become an active area of research due to deep learning requiring huge amounts of labeled dataset, which is not feasible in the real world. Learning from a few examples is also an important attempt towards learning like humans. Few-shot learning has proven a very good promise in different areas of machine learning applications, particularly in image classification. As it is a recent technique, most researchers focus on understanding and solving the issues related to its concept by focusing only on common image datasets like Mini-ImageNet and Omniglot. Few-shot learning also opens an opportunity to address low resource languages like Amharic. In this study, offline handwritten Amharic character recognition using few-shot learning is addressed. Particularly, prototypical networks, the popular and simpler type of fewshot learning, is implemented as a baseline. Using the opportunities explored in the nature of Amharic alphabet having row-wise and columnwise similarities, a novel way of augmenting the training episodes is proposed. The experimental results show that the proposed method outperformed the baseline method. This study has implemented few-shot learning for Amharic characters for the first time. More importantly, the findings of the study open new ways of examining the influence of training episodes in few-shot learning, which is one of the important issues that needs exploration. The datasets used for this study are collected from native Amharic language writers using an Android App developed as a part of this study.},
	author = {Samuel, Mesay and Schmidt-Thieme, Lars and Sharma, D. P. and Sinamo, Abiot and Bruck, Abey},
	date-added = {2023-05-27 07:37:03 +0200},
	date-modified = {2023-05-27 07:37:03 +0200},
	file = {Samuel et al. - 2022 - Offline Handwritten Amharic Character Recognition .pdf:/Users/maximilianslapnik/Zotero/storage/89MEREMV/Samuel et al. - 2022 - Offline Handwritten Amharic Character Recognition .pdf:application/pdf},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	language = {en},
	month = oct,
	note = {arXiv:2210.00275 [cs]},
	publisher = {arXiv},
	title = {Offline {Handwritten} {Amharic} {Character} {Recognition} {Using} {Few}-shot {Learning}},
	url = {http://arxiv.org/abs/2210.00275},
	urldate = {2023-05-27},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2210.00275}}

@incollection{feris_embarrassingly_2015,
	abstract = {Zero-shot learning consists in learning how to recognise new concepts by just having a description of them. Many sophisticated approaches have been proposed to address the challenges this problem comprises. In this paper we describe a zero-shot learning approach that can be implemented in just one line of code, yet it is able to outperform state of the art approaches on standard datasets. The approach is based on a more general framework which models the relationships between features, attributes, and classes as a two linear layers network, where the weights of the top layer are not learned but are given by the environment. We further provide a learning bound on the generalisation error of this kind of approaches, by casting them as domain adaptation methods. In experiments carried out on three standard real datasets, we found that our approach is able to perform significantly better than the state of art on all of them, obtaining a ratio of improvement up to 17\%.},
	author = {Romera-Paredes, Bernardino and Torr, Philip H. S.},
	date-added = {2023-05-25 21:15:19 +0200},
	date-modified = {2023-05-25 21:15:19 +0200},
	doi = {10.1007/978-3-319-50077-5_2},
	editor = {Feris, Rogerio Schmidt and Lampert, Christoph and Parikh, Devi},
	file = {Romera-Paredes and Torr - 2017 - An Embarrassingly Simple Approach to Zero-Shot Lea.pdf:/Users/maximilianslapnik/Zotero/storage/JZKMIAID/Romera-Paredes and Torr - 2017 - An Embarrassingly Simple Approach to Zero-Shot Lea.pdf:application/pdf},
	isbn = {978-3-319-50075-1 978-3-319-50077-5},
	language = {en},
	note = {Series Title: Advances in Computer Vision and Pattern Recognition},
	title = {An {Embarrassingly} {Simple} {Approach} to {Zero}-{Shot} {Learning}},
	url = {http://link.springer.com/10.1007/978-3-319-50077-5_2},
	urldate = {2023-05-25},
	year = {2015},
	bdsk-url-1 = {http://link.springer.com/10.1007/978-3-319-50077-5_2},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-50077-5_2}}

@misc{dang_how_2022,
	abstract = {Deep generative models have the potential to fundamentally change the way we create high-fidelity digital content but are often hard to control. Prompting a generative model is a promising recent development that in principle enables end-users to creatively leverage zero-shot and few-shot learning to assign new tasks to an AI adhoc, simply by writing them down. However, for the majority of end-users writing effective prompts is currently largely a trial and error process. To address this, we discuss the key opportunities and challenges for interactive creative applications that use prompting as a new paradigm for Human-AI interaction. Based on our analysis, we propose four design goals for user interfaces that support prompting. We illustrate these with concrete UI design sketches, focusing on the use case of creative writing. The research community in HCI and AI can take these as starting points to develop adequate user interfaces for models capable of zero- and few-shot learning.},
	author = {Dang, Hai and Mecke, Lukas and Lehmann, Florian and Goller, Sven and Buschek, Daniel},
	date-added = {2023-05-25 15:24:09 +0200},
	date-modified = {2023-05-25 15:24:09 +0200},
	file = {Dang et al. - 2022 - How to Prompt Opportunities and Challenges of Zer.pdf:/Users/maximilianslapnik/Zotero/storage/5GAGBIJM/Dang et al. - 2022 - How to Prompt Opportunities and Challenges of Zer.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, H.5.2, I.2.7},
	language = {en},
	month = sep,
	note = {arXiv:2209.01390 [cs]},
	publisher = {arXiv},
	shorttitle = {How to {Prompt}?},
	title = {How to {Prompt}? {Opportunities} and {Challenges} of {Zero}- and {Few}-{Shot} {Learning} for {Human}-{AI} {Interaction} in {Creative} {Applications} of {Generative} {Models}},
	url = {http://arxiv.org/abs/2209.01390},
	urldate = {2023-05-18},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2209.01390}}

@misc{shuster_blenderbot_2022,
	abstract = {We present BlenderBot 3, a 175B parameter dialogue model capable of open-domain conversation with access to the internet and a longterm memory, and having been trained on a large number of user defined tasks. We release both the model weights and code, and have also deployed the model on a public web page to interact with organic users. This technical report describes how the model was built (architecture, model and training scheme), and details of its deployment, including safety mechanisms. Human evaluations show its superiority to existing open-domain dialogue agents, including its predecessors (Roller et al., 2021; Komeili et al., 2022). Finally, we detail our plan for continual learning using the data collected from deployment, which will also be publicly released. The goal of this research program is thus to enable the community to study ever-improving responsible agents that learn through interaction.},
	author = {Shuster, Kurt and Xu, Jing and Komeili, Mojtaba and Ju, Da and Smith, Eric Michael and Roller, Stephen and Ung, Megan and Chen, Moya and Arora, Kushal and Lane, Joshua and Behrooz, Morteza and Ngan, William and Poff, Spencer and Goyal, Naman and Szlam, Arthur and Boureau, Y.-Lan and Kambadur, Melanie and Weston, Jason},
	date-added = {2023-05-24 19:01:50 +0200},
	date-modified = {2023-05-24 19:01:50 +0200},
	file = {Shuster et al. - 2022 - BlenderBot 3 a deployed conversational agent that.pdf:/Users/maximilianslapnik/Zotero/storage/DIDB6ZFQ/Shuster et al. - 2022 - BlenderBot 3 a deployed conversational agent that.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	language = {en},
	month = aug,
	note = {arXiv:2208.03188 [cs]},
	publisher = {arXiv},
	shorttitle = {{BlenderBot} 3},
	title = {{BlenderBot} 3: a deployed conversational agent that continually learns to responsibly engage},
	url = {http://arxiv.org/abs/2208.03188},
	urldate = {2023-05-24},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2208.03188}}

@misc{glaese_improving_2022,
	abstract = {We present Sparrow, an information-seeking dialogue agent trained to be more helpful, correct, and harmless compared to prompted language model baselines. We use reinforcement learning from human feedback to train our models with two new additions to help human raters judge agent behaviour. First, to make our agent more helpful and harmless, we break down the requirements for good dialogue into natural language rules the agent should follow, and ask raters about each rule separately. We demonstrate that this breakdown enables us to collect more targeted human judgements of agent behaviour and allows for more efficient rule-conditional reward models. Second, our agent provides evidence from sources supporting factual claims when collecting preference judgements over model statements. For factual questions, evidence provided by Sparrow supports the sampled response 78\% of the time. Sparrow is preferred more often than baselines while being more resilient to adversarial probing by humans, violating our rules only 8\% of the time when probed. Finally, we conduct extensive analyses showing that though our model learns to follow our rules it can exhibit distributional biases.},
	author = {Glaese, Amelia and McAleese, Nat and Tr{\k e}bacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and Campbell-Gillingham, Lucy and Uesato, Jonathan and Huang, Po-Sen and Comanescu, Ramona and Yang, Fan and See, Abigail and Dathathri, Sumanth and Greig, Rory and Chen, Charlie and Fritz, Doug and Elias, Jaume Sanchez and Green, Richard and Mokr{\'a}, So{\v n}a and Fernando, Nicholas and Wu, Boxi and Foley, Rachel and Young, Susannah and Gabriel, Iason and Isaac, William and Mellor, John and Hassabis, Demis and Kavukcuoglu, Koray and Hendricks, Lisa Anne and Irving, Geoffrey},
	date-added = {2023-05-24 18:59:55 +0200},
	date-modified = {2023-05-24 18:59:55 +0200},
	file = {Glaese et al. - 2022 - Improving alignment of dialogue agents via targete.pdf:/Users/maximilianslapnik/Zotero/storage/AK7V6HH5/Glaese et al. - 2022 - Improving alignment of dialogue agents via targete.pdf:application/pdf},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	language = {en},
	month = sep,
	note = {arXiv:2209.14375 [cs]},
	publisher = {arXiv},
	title = {Improving alignment of dialogue agents via targeted human judgements},
	url = {http://arxiv.org/abs/2209.14375},
	urldate = {2023-05-24},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2209.14375}}

@misc{thoppilan_lamda_2022,
	abstract = {We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformerbased neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency.},
	author = {Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and Li, YaGuang and Lee, Hongrae and Zheng, Huaixiu Steven and Ghafouri, Amin and Menegali, Marcelo and Huang, Yanping and Krikun, Maxim and Lepikhin, Dmitry and Qin, James and Chen, Dehao and Xu, Yuanzhong and Chen, Zhifeng and Roberts, Adam and Bosma, Maarten and Zhao, Vincent and Zhou, Yanqi and Chang, Chung-Ching and Krivokon, Igor and Rusch, Will and Pickett, Marc and Srinivasan, Pranesh and Man, Laichee and Meier-Hellstern, Kathleen and Morris, Meredith Ringel and Doshi, Tulsee and Santos, Renelito Delos and Duke, Toju and Soraker, Johnny and Zevenbergen, Ben and Prabhakaran, Vinodkumar and Diaz, Mark and Hutchinson, Ben and Olson, Kristen and Molina, Alejandra and Hoffman-John, Erin and Lee, Josh and Aroyo, Lora and Rajakumar, Ravi and Butryna, Alena and Lamm, Matthew and Kuzmina, Viktoriya and Fenton, Joe and Cohen, Aaron and Bernstein, Rachel and Kurzweil, Ray and Aguera-Arcas, Blaise and Cui, Claire and Croak, Marian and Chi, Ed and Le, Quoc},
	date-added = {2023-05-24 18:50:43 +0200},
	date-modified = {2023-05-24 18:50:43 +0200},
	file = {Thoppilan et al. - 2022 - LaMDA Language Models for Dialog Applications.pdf:/Users/maximilianslapnik/Zotero/storage/PD4FXT6T/Thoppilan et al. - 2022 - LaMDA Language Models for Dialog Applications.pdf:application/pdf},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	language = {en},
	month = feb,
	note = {arXiv:2201.08239 [cs]},
	publisher = {arXiv},
	shorttitle = {{LaMDA}},
	title = {{LaMDA}: {Language} {Models} for {Dialog} {Applications}},
	url = {http://arxiv.org/abs/2201.08239},
	urldate = {2023-05-24},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2201.08239}}

@article{radford_improving_2018,
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	date-added = {2023-05-24 18:28:22 +0200},
	date-modified = {2023-05-24 18:28:22 +0200},
	file = {Radford et al. - Improving Language Understanding by Generative Pre.pdf:/Users/maximilianslapnik/Zotero/storage/BNIVP4RK/Radford et al. - Improving Language Understanding by Generative Pre.pdf:application/pdf},
	language = {en},
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	year = {2018}}

@article{vaswani_attention_2017,
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	date-added = {2023-05-24 18:15:01 +0200},
	date-modified = {2023-05-24 18:15:01 +0200},
	file = {Vaswani et al. - Attention is All you Need.pdf:/Users/maximilianslapnik/Zotero/storage/S7NUJBLF/Vaswani et al. - Attention is All you Need.pdf:application/pdf},
	language = {en},
	title = {Attention is {All} you {Need}},
	volume = {30},
	year = {2017}}

@inproceedings{lee_coauthor_2022,
	abstract = {Large language models (LMs) ofer unprecedented language generation capabilities and exciting opportunities for interaction design. However, their highly context-dependent capabilities are difcult to grasp and are often subjectively interpreted. In this paper, we argue that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs' generative capabilities. Exemplifying this approach, we present CoAuthor, a dataset designed for revealing GPT-3's capabilities in assisting creative and argumentative writing. CoAuthor captures rich interactions between 63 writers and four instances of GPT-3 across 1445 writing sessions. We demonstrate that CoAuthor can address questions about GPT-3's language, ideation, and collaboration capabilities, and reveal its contribution as a writing ``collaborator'' under various defnitions of good collaboration. Finally, we discuss how this work may facilitate a more principled discussion around LMs' promises and pitfalls in relation to interaction design. The dataset and an interface for replaying the writing sessions are publicly available at https://coauthor.stanford.edu.},
	address = {New Orleans LA USA},
	author = {Lee, Mina and Liang, Percy and Yang, Qian},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	date-added = {2023-05-24 17:09:00 +0200},
	date-modified = {2023-05-24 17:09:00 +0200},
	doi = {10.1145/3491102.3502030},
	file = {Lee et al. - 2022 - CoAuthor Designing a Human-AI Collaborative Writi.pdf:/Users/maximilianslapnik/Zotero/storage/B58HKHBC/Lee et al. - 2022 - CoAuthor Designing a Human-AI Collaborative Writi.pdf:application/pdf},
	isbn = {978-1-4503-9157-3},
	language = {en},
	month = apr,
	pages = {1--19},
	publisher = {ACM},
	shorttitle = {{CoAuthor}},
	title = {{CoAuthor}: {Designing} a {Human}-{AI} {Collaborative} {Writing} {Dataset} for {Exploring} {Language} {Model} {Capabilities}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3502030},
	urldate = {2023-05-18},
	year = {2022},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/3491102.3502030},
	bdsk-url-2 = {https://doi.org/10.1145/3491102.3502030}}

@misc{openai_chatgpt_2023,
	author = {{OpenAI}},
	date-added = {2023-05-24 16:48:23 +0200},
	date-modified = {2023-05-24 16:48:23 +0200},
	file = {ChatGPT | OpenAI:/Users/maximilianslapnik/Zotero/storage/SNJ44DY6/login.html:text/html},
	title = {{ChatGPT}},
	url = {https://chat.openai.com/auth/login},
	urldate = {2023-05-24},
	year = {2023},
	bdsk-url-1 = {https://chat.openai.com/auth/login}}
