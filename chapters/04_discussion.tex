%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DISCUSSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
\label{sec:discussion}
% 1. Why do users interact with LLMs the way they do? Reasoning and informed assumptions on the
% causes of observed behavior
% 2. Prompt Improvement Possibilities Proposition of ways to enhance prompts as well as associated
% results based on findings from related researc

% first ChatGPT, then Midjourney analysis, then comparison?

\subsection{Data Synthesis: Commonalities, Differences, and Possible Explanations}
\label{subsec:data-synthesis:-commonalities-differences-and-possible-explanations}
In this section, we reason about the observed behavior from the two data sources and try to offer
informed assumptions on potential causes.

\subsubsection{ChatGPT Behavior}
In regard to the type of prompt, we observed mainly task-based and question-related queries from
users.
This leads us to imagine that some users treat LLMs such as ChatGPT increasingly as their
personal online assistant when it comes to executing various tasks the model might be able to solve.
Leveraging AI bots as assistants of the future is a use case that gains popularity, and that is also
increasingly researched~\cite{eshghie_chatgpt_2023}.
The second most prevalent type of prompt were questions.
We have already mentioned, that NLP models might replace current search engines in the future.
This belief is further confirmed by observations from other researches who already see this
emerging trend in user behavior~\cite{van_bulck_what_2023}.
Regarding prompt intent, looking for information was the most popular use case.
Seemingly, users see ChatGPT as a reliable source of knowledge and trust its abilities.
This assumption can be dangerous however, as it is well-known that every LLM is probabilistic and
only as good as its training data.
Results should therefore always be verified.
Based on the fact that a lot of users also relied on ChatGPT for suggestions, we assume that it
is gladly used as a means to get ahead when you hit roadblocks, or need support in endeavours
that require creativity.
As we already touched on above, we did not have any requests for opinions of the model.
We would have thought that opinion related requests on difficult, morally complex, or
controversial topics would be more popular, since such behavior could be observed a lot online when
users tried to test the limits of the model, or for example when researchers tested political
biases~\cite{rozado_political_2023}.
Regarding the prompt setting, we made an observation similar to Brown et al.~\cite{
    brown_language_2020}.
Users do not leverage effective prompting techniques such as a few-shot approach.
Instead, they relied heavily (90\%) on zero shot prompts.
We attribute this behavior to missing awareness of users about optimized techniques, and
therefore recommend that LLM providers actively make users actively inform users, e.g. by
providing examples, or releasing guidelines.
Our observations when looking at user engagement makes us think that current LLMs are already
quite accurate: almost half of the users finished the conversation after the initial answer of
the LLM (single turn).
This is further reinforced by 66\% of prompts that were not refined.
We therefore suspect, that most of the time the users were actually content with the results.
However, we have to mention the possibility that the initial answer was so far off,
that users might have stopped trying after the first attempt.
Overall, we reckon that users prefer to leverage LLMs for rather simple tasks.
It is difficult to say, whether users do not trust LLMs enough to throw complex questions at
them yet, or if it simply is in the nature of online search requests, that the majority of search
requests that users look up are more of a simple nature than very complex.
Few users refine their prompts (66\% do not).
Related work suggests that refining queries has led to improved results when using search
engines.
LLMs can be improved by refinements too, since models are “primed” by all previous prompts in
the interaction, so even if a model does not initially do what you want it to, it might make
sense to give it more information or context, and try again.
Due to missing sentiments and feedback of users in the sample interactions, we cannot reliably say
if users were simply always content because they did not refine, or if they did not know that
continuing the interaction with the model could have led to better results.
Finally, we have generally observed a majority of formal, generally polite, and acceptable language.
We reason that the use of such language ties in with our first observation, and reckon users may see
the bot as a personal companion, that you therefore treat well in interactions.

\subsubsection{Midjourney Behavior}
For Midjourney, we identified a majority of language inputs.
We assume, this tendency exists because users prefer to create something new instead
of reworking existing images.
We imagine AI could eventually revolutionise the image editing market as well, but does not seem
to be quite there yet, probably due to missing accuracy when trying to make only very small
adjustments.
Regarding prompt length, the official Midjourney docs state: \("\)The Midjourney Bot works best with
simple, short sentences that describe what you want to see\("\)~\cite{midjourney_documentation_2023}.
Long sentences should be avoided, but we have seen users ignore this advice multiple times.
There sometimes seems to be a lack of understanding that more information is not
always better for quality of model outputs.
This observation fits another that has been made before:
Users struggle to formulate precise, effective, and therefore also short, concise prompts.
We suggested better learning materials and guidance already to address this issue.

\subsubsection{Commonalities and Differences between ChatGPT and Midjourney}
