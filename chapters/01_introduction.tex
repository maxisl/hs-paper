%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}
%% refer to https://intra.ece.ucr.edu/~rlake/Whitesides_writing_res_paper.pdf for tips on introduction?
%% INTRO - TOPIC

%Why is the work important?
\sloppy % use sloppy to improve linebreaks - longer words do not overflow
Artificial Intelligence (AI) -based tools continually gain prominence as regularly leveraged tools in the
daily lives of millions of people.
Today, the significance of this technology is reflected in the current AI market size that is
estimated to be \$142 billion USD, and forecasted to increase more than tenfold by 2030~\cite{statista_artificial_2023}.
% TODO include some stats, such as daily ChatGPT users?
In addition to typical AI applications such as recommendation systems or autonomous agents, generative
models are notably increasing in popularity as well, making it one of the central research topics
in the field.
One of the most widely used implementations of generative models are Large Language Models (LLMs),
the most popular example at the moment being OpenAI's ChatGPT~\cite{openai_chatgpt_2023}.
Adoption rates of generative AI applications among professionals are increasing rapidly, and are
already at
around 30\%~\cite{statista_us_2022}.

Large Language Models are mainly implemented in the form of text generating chatbots that can
answer seemingly any question a user might pose.
Although no expert knowledge is required to formulate a prompt and interact with an LLM-based bot, it is challenging to optimize the output, since it varies depending on the structure, wording,
and composition of the input. %TODO cite?
Any form of model input, whether it is in the form of a task or a question, is commonly
referred to as \("\)prompting\("\) the model.
Due to the vast application possibilities and promising future developments of LLMs, exploration of
user prompting behavior in interactions with such models is of particular interest.
Plenty of research has been conducted in the field of user interactions with LLMs already,
mainly in regard to query reformulation strategies, studies of common user errors when prompting,
different prompt composition strategies, and general LLM limitations.

%- The objectives of the work.
In this paper, we are going to explain the fundamentals and workings of LLMs and prompting,
describe related research in the realm of user - LLM exchange, and perform our own investigation of
user behavior in such interactions.
This investigation has the objective of facilitating comprehension of existing challenges users
face when dealing with Large Language Models.
Furthermore, readers will gain a better understanding of the design of effective prompts that
enhance model output.

%- Guidance to the reader:
% What should the reader watch for in the paper?
% What are the interesting high points? What strategy did we use?
Since the main part of this paper will be complemented by an analysis of real-world examples, the
reader can expect to develop an enhanced comprehension of actual user prompting behavior.
To obtain these insights, we will leverage input data mainly gathered from the website
ShareGPT~\cite{sharegpt_sharegpt_2023},
which enables users to store conversations they have had with the ChatGPT model for later retrieval
or sharing them publicly.

% TODO add links (\ref) to sections
The paper is organized as follows.
This introduction is succeeded by a related work section that sets the context for all subsequent
parts by first focusing on Large Language Models (LLMs) and covering general information about
their workings, training data, text generation capabilities, real-world usage, and current limitations.
We then explore user interactions with LLMs, explain the concept of prompting, and highlight
various use cases as well as related research.

The next section introduces the study by outlining the research objective and
describing the methodology and individual steps that will be taken.
It then focuses on the research method we use, as well as the ShareGPT and Midjourney platforms,
which provide the input data for the study.

Subsequently, we present our findings.
To do so, we first list the study results, organized into predefined categories.
% TODO check if true
We then analyze observable trends in user behavior and data patterns.

The following discussion section starts with a synthesis of our observations.
We then go into more detail about the reasons why users interact with LLMs the way they do,
offering reasoning and informed assumptions.
Additionally, we explore possibilities for prompt improvements based on findings from related
research.

In the outlook section, we provide a perspective on future developments, divided into an
introduction of the concept of Auto-GPT as a possible future iteration of prompting, as well as an
overview of prompt engineering as a newly emerging discipline in the technology sector.

The final section of this paper offers a consolidation of the findings and associated discussions,
as well as a summary of how we could recognize findings from related research in our own input
samples.