%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Background %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}
\label{sec:background}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LLMs %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Large Language Models (LLMs)}
\label{subsec:large-language-models-(llms)}
% TODO too repetitive?
One of the most widely used applications areas of generative AI are Large Language Models (LLMs).
Among LLMs, the most widely adopted is ChatGPT~\cite{openai_chatgpt_2023}, which is a
conversational model being developed by OpenAI\@.
The model is currently publicly accessible and free of charge.

% What is an LLM? What does it look like?
LLMs can be leveraged for a variety of tasks, but their main focus area is Natural Language Processing
(NLP).
Therefore, most LLMs designed for end users are implemented in the form of chatbots,
as is the case with ChatGPT for example.
They typically consist of an interface comprised of an input field for the user to type in arbitrary
text, as well as an output section that displays generated responses of the model.

% How does an LLM / ChatGPT work?
Large Language Models are a recent advancement that followed the development of the original
transformer architecture, which is a deep learning approach first introduced by researchers in 2017~\cite{vaswani_attention_2017}.
In future iterations, the Generative Pre-Training (GPT)~\cite{radford_improving_2018} approach
was adapted for text-based models in particular, laying the foundation for today's most
popular conversational LLMs, such as ChatGPT\@.
Since our research revolves around user interaction with dialog-focused models, we will not go into
more detail about other application and development areas of LLMs.
In addition to ChatGPT, there are also a variety of similar other models focused on text generation,
such as LaMDA~\cite{thoppilan_lamda_2022}, Sparrow~\cite{glaese_improving_2022}, or
BlenderBot 3~\cite{shuster_blenderbot_2022}.


% Why are LLMs important for our work? How do they come into play?
LLMs are a central part of our research as we investigate user behavior in LLM conversations.
Currently, there are no binding guidelines on usage and prompting of such models,
and users are therefore completely unconfined in their way of interacting with them.


\subsubsection{Zero-Shot Learning} % TODO Zero-Shot prompting?
It is important to clarify different possible forms of prompting that exist in LLM interactions in order
to be able to correctly analyze and assess prompts in later parts of this paper.
In the following, we will clarify the terms \("\)Zero-Shot-\("\) as well as \("\)Few-Shot Learning\("\).
Zero-Shot Learning has been described as \("\)[\ldots] learning how to recognise
new concepts by just having a description of them\("\)\cite[p. 1]{feris_embarrassingly_2015}.
In our case, we refer to any form of prompt where the user does not specify a particular example as
part of the query~\cite[p. 1]{dang_how_2022}.
An example for such a query could be \("\)Give me five examples of papers that deal with the topic
of LLMs\("\).

\subsubsection{Few-Shot Learning}
In a Few-Shot Learning setting in contrast, the user does provide examples for the model.
Doing so can help improve model outputs~\cite[p. 1]{dang_how_2022}.
